model:
  layers:
    - dense:
        units: 64
        activation: relu
        input_shape: [2]
    - dense:
        units: 64
        activation: relu
    - dense:
        units: 3
        activation: linear

training:
  optimizer: adam
  loss: mse
  metrics: [mae]
  num_episodes: 2000
  max_steps: 200
  gamma: 0.99
  epsilon_decay: 0.995
  epsilon_min: 0.01
  learning_rate: 0.001

data:
  normalize: true
  dataset: mountain_car
  input_shape: [2]
  batch_size: 64
  buffer_size: 100000

testing:
  num_episodes: 100
  max_steps: 200
  loss: categorical_crossentropy 
  metrics: [accuracy]  
  num_episodes: 1000
  max_steps: 300
  epochs: 100
  validation_split: 0.2
  callbacks:
    checkpoint:
        enabled: true
    early_stopping:
        enabled: true
        patience: 20
    tensorboard:
        enabled: true
    regularization:
        enabled: true
        l1: 0.0001
        l2: 0.0001
    lr_scheduler:
        enabled: true
        lr: 0.001
        lr_step_size: 1
        lr_decay_rate: 0.995
        type: exponential
  gamma: 0.99
data:
  normalize: true
  dataset: mountain_car
  input_shape: [2]
  batch_size: 32
  shuffle: true
  seed: 42
  buffer_size: 1500

testing:
  num_episodes: 100
  max_steps: 200